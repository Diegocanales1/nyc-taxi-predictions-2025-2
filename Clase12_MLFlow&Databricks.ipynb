{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tarea y actividad en clase.\n",
    "\n",
    "1. Hacer merge de la rama que trabajamos a main.\n",
    "2. Crear una nueva rama que se llame `feat: tarea 5`.\n",
    "3. Crear un nuevo `jupyter-notebook` llamado `challenger-experiments.ipynb` en la rama creada anteriormente\n",
    "4. Hacer dos `parent experiments` con `Gradient Boost` y `Random Forest` regressors en donde cada uno tenga `child experiments` con b√∫squeda de hyper-par√°metros. Puede usar cualquier librerar√≠a con la que se sienta c√≥modo: `hyperopt`, `optuna`, `scikit-learn` (Grid Search, Random Search, Halving Search etc)\n",
    "5. Registrar el modelo con la mejor m√©trica `validation-rmse` de los obtenidos en dichos experimentos en el `model registry` en el mismo modelo ya previamente creado `nyc-taxi-model`.\n",
    "6. As√≠gnele el alias `challenger`\n",
    "7. Descargue en la carpeta `data` el conjunto de datos correspondiente a marzo del 2025\n",
    "9. Use ese conjunto de datos para probarlo sobre los modelos con el alias `champion` y `challenger`\n",
    "10. Obtenga la m√©trica de cada modelo\n",
    "11. Decida si el nuevo modelo `challenger` debe ser promovido a `champion` o no. Use los criterios que usted como Data Scientis considere relevantes y justifique la respuesta.\n",
    "12. Abrir un `PR` con los cambios hechos en la rama `feat: tarea 5` hacia la rama `main`.\n",
    "\n",
    "\n",
    "Habr√° dos entregas divididas de la siguiente manera:\n",
    "\n",
    "1. **Trabajo en clase hoy Martes 21 de Octubre de 2025.** Para esta entrega, hacer un commit con el siguiente mensaje `feat: entrega trabajo en clase` con los avances realizados en clase.\n",
    "\n",
    "2. **Tarea: Martes 28 de Octubre de 2025 a las 19:55.** Esta entrega debe contener todo lo descrito anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import  root_mean_squared_error\n",
    "from sklearn.feature_extraction import  DictVectorizer\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('data/green_tripdata_2025-01.parquet')\n",
    "df_val = read_dataframe('data/green_tripdata_2025-02.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering + One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, dv):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dv.transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "X_val = preprocess(df_val, dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los `dataset` como objetos de `mlflow` para poderlos trackear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2025-01\")\n",
    "validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2025-02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Tunning de Hiper-par√°metros para un modelo `xgboost` - Optuna\n",
    "\n",
    "El **tunning de hiper-par√°metros** consiste en encontrar la mejor combinaci√≥n de par√°metros que optimizan el rendimiento de un modelo.\n",
    "\n",
    "En lugar de probar valores manualmente, usamos librer√≠as como **Optuna**, que aplican estrategias inteligentes de b√∫squeda (*Bayesian optimization*, *Tree-structured Parzen Estimator*, etc.) para acelerar el proceso y encontrar resultados m√°s robustos.\n",
    "\n",
    "En este caso, usaremos **Optuna** para ajustar un modelo de **XGBoost**, definiendo un espacio de b√∫squeda para par√°metros como:\n",
    "| Par√°metro | Descripci√≥n |\n",
    "|------------|--------------|\n",
    "| `max_depth` | Profundidad m√°xima de los √°rboles | \n",
    "| `learning_rate` | Tasa de aprendizaje (escala logar√≠tmica) | \n",
    "| `reg_alpha` | Regularizaci√≥n L1 (Œ±) | \n",
    "| `reg_lambda` | Regularizaci√≥n L2 (Œª) | \n",
    "| `min_child_weight` | Peso m√≠nimo de muestras por hoja | \n",
    "| `objective` | Funci√≥n objetivo | \n",
    "| `seed` | Semilla aleatoria | \n",
    "\n",
    "Durante el proceso, Optuna crea un **‚Äústudy‚Äù** donde cada *trial* representa una combinaci√≥n de par√°metros probada.  \n",
    "\n",
    "Cada *trial* puede registrarse con **MLflow**, lo que permite visualizar m√©tricas, comparar resultados y seleccionar el modelo m√°s prometedor.\n",
    "\n",
    "Ejemplo simplificado de estructura:\n",
    "\n",
    "```python\n",
    "import math, optuna, xgboost as xgb, mlflow\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", math.exp(-3), 1.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", math.exp(-5), math.exp(-1), log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", math.exp(-6), math.exp(-1), log=True),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", math.exp(-1), math.exp(3), log=True),\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(params, dtrain, evals=[(dvalid, \"validation\")])\n",
    "        preds = booster.predict(dvalid)\n",
    "        rmse = mean_squared_error(y_valid, preds, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "    return rmse\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "```\n",
    "\n",
    "üîπ **Ventajas de usar Optuna con MLflow:**\n",
    "- Seguimiento autom√°tico de m√©tricas y par√°metros.  \n",
    "- Comparaci√≥n visual de resultados en la UI de MLflow.  \n",
    "- Integraci√≥n fluida con Databricks y notebooks colaborativos.  \n",
    "\n",
    "---\n",
    "\n",
    "üìö **Referencia interesante:**  \n",
    "üëâ [https://xgboosting.com/](https://xgboosting.com/) ‚Äî Gu√≠a pr√°ctica con ejemplos avanzados de *tunning* y t√©cnicas modernas para modelos de **XGBoost** y **Optuna**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import optuna\n",
    "import pathlib\n",
    "import xgboost as xgb\n",
    "from optuna.samplers import TPESampler\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funci√≥n Objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Definir la funci√≥n objetivo para Optuna\n",
    "#    - Recibe un `trial`, que se usa para proponer hiperpar√°metros.\n",
    "#    - Entrena un modelo con esos hiperpar√°metros.\n",
    "#    - Calcula la m√©trica de validaci√≥n (RMSE) y la retorna (Optuna la minimizar√°).\n",
    "#    - Abrimos un run anidado de MLflow para registrar cada trial.\n",
    "# ------------------------------------------------------------\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    # Hiperpar√°metros MUESTREADOS por Optuna en CADA trial.\n",
    "    # Nota: usamos log=True para emular rangos log-uniformes (similar a loguniform).\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", math.exp(-3), 1.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\",   math.exp(-5), math.exp(-1), log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", math.exp(-6), math.exp(-1), log=True),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", math.exp(-1), math.exp(3), log=True),\n",
    "        \"objective\": \"reg:squarederror\",  \n",
    "        \"seed\": 42,                      \n",
    "    }\n",
    "\n",
    "    # Run anidado para dejar rastro de cada trial en MLflow\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"model_family\", \"xgboost\")  # etiqueta informativa\n",
    "        mlflow.log_params(params)                  # registra hiperpar√°metros del trial\n",
    "\n",
    "        # Entrenamiento con early stopping en el conjunto de validaci√≥n\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, \"validation\")],\n",
    "            early_stopping_rounds=10,\n",
    "        )\n",
    "\n",
    "        # Predicci√≥n y m√©trica en validaci√≥n\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "        # Registrar la m√©trica principal\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # La \"signature\" describe la estructura esperada de entrada y salida del modelo:\n",
    "        # incluye los nombres, tipos y forma (shape) de las variables de entrada y el tipo de salida.\n",
    "        # MLflow la usa para validar datos en inferencia y documentar el modelo en el Model Registry.\n",
    "        signature = infer_signature(X_val, y_pred)\n",
    "\n",
    "        # Guardar el modelo del trial como artefacto en MLflow.\n",
    "        mlflow.xgboost.log_model(\n",
    "            booster,\n",
    "            name=\"model\",\n",
    "            input_example=X_val[:5],\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "    # Optuna minimiza el valor retornado\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flujo de b√∫squeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 18:36:04,530] A new study created in memory with name: no-name-1c29518c-e290-4068-a510-ae5188cbb4e7\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Could not find experiment with ID 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      9\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m, sampler=sampler)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Ejecutar la optimizaci√≥n (n_trials = n√∫mero de intentos)\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#    - Cada trial ejecuta la funci√≥n objetivo con un set distinto de hiperpar√°metros.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#    - Abrimos un run \"padre\" para agrupar toda la b√∫squeda.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# ------------------------------------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mXGBoost Hyperparameter Optimization (Optuna)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[32m     17\u001b[39m     study.optimize(objective, n_trials=\u001b[32m10\u001b[39m)\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# --------------------------------------------------------\u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# Recuperar y registrar los mejores hiperpar√°metros\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# --------------------------------------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\canal\\miniconda3\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:475\u001b[39m, in \u001b[36mstart_run\u001b[39m\u001b[34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[39m\n\u001b[32m    471\u001b[39m         user_specified_tags[MLFLOW_RUN_NAME] = run_name\n\u001b[32m    473\u001b[39m     resolved_tags = context_registry.resolve_tags(user_specified_tags)\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     active_run_obj = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexp_id_for_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolved_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m log_system_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# If `log_system_metrics` is not specified, we will check environment variable.\u001b[39;00m\n\u001b[32m    483\u001b[39m     log_system_metrics = MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING.get()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\canal\\miniconda3\\Lib\\site-packages\\mlflow\\tracking\\client.py:479\u001b[39m, in \u001b[36mMlflowClient.create_run\u001b[39m\u001b[34m(self, experiment_id, start_time, tags, run_name)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_run\u001b[39m(\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    427\u001b[39m     experiment_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    430\u001b[39m     run_name: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    431\u001b[39m ) -> Run:\n\u001b[32m    432\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    433\u001b[39m \u001b[33;03m    Create a :py:class:`mlflow.entities.Run` object that can be associated with\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[33;03m    metrics, parameters, artifacts, etc.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    477\u001b[39m \u001b[33;03m        status: RUNNING\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\canal\\miniconda3\\Lib\\site-packages\\mlflow\\telemetry\\track.py:30\u001b[39m, in \u001b[36mrecord_usage_event.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m start_time = time.time()\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result  \u001b[38;5;66;03m# noqa: RET504\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\canal\\miniconda3\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:183\u001b[39m, in \u001b[36mTrackingServiceClient.create_run\u001b[39m\u001b[34m(self, experiment_id, start_time, tags, run_name)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# Extract user from tags\u001b[39;00m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# This logic is temporary; the user_id attribute of runs is deprecated and will be removed\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# in a later release.\u001b[39;00m\n\u001b[32m    181\u001b[39m user_id = tags.get(MLFLOW_USER, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRunTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\canal\\miniconda3\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:689\u001b[39m, in \u001b[36mFileStore.create_run\u001b[39m\u001b[34m(self, experiment_id, user_id, start_time, tags, run_name)\u001b[39m\n\u001b[32m    685\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    686\u001b[39m \u001b[33;03mCreates a run with the specified attributes.\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    688\u001b[39m experiment_id = FileStore.DEFAULT_EXPERIMENT_ID \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m experiment = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    691\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    692\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not create run under experiment with ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - no such \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    693\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mexperiment exists.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    694\u001b[39m         databricks_pb2.RESOURCE_DOES_NOT_EXIST,\n\u001b[32m    695\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\canal\\miniconda3\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:498\u001b[39m, in \u001b[36mFileStore.get_experiment\u001b[39m\u001b[34m(self, experiment_id)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03mFetch the experiment.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03mNote: This API will search for active as well as deleted experiments.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    495\u001b[39m \u001b[33;03m    A single Experiment object if it exists, otherwise raises an Exception.\u001b[39;00m\n\u001b[32m    496\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    497\u001b[39m experiment_id = FileStore.DEFAULT_EXPERIMENT_ID \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m experiment = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    500\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    501\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExperiment \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m does not exist.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    502\u001b[39m         databricks_pb2.RESOURCE_DOES_NOT_EXIST,\n\u001b[32m    503\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\canal\\miniconda3\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:462\u001b[39m, in \u001b[36mFileStore._get_experiment\u001b[39m\u001b[34m(self, experiment_id, view_type)\u001b[39m\n\u001b[32m    460\u001b[39m experiment_dir = \u001b[38;5;28mself\u001b[39m._get_experiment_path(experiment_id, view_type)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m experiment_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    463\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find experiment with ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    464\u001b[39m         databricks_pb2.RESOURCE_DOES_NOT_EXIST,\n\u001b[32m    465\u001b[39m     )\n\u001b[32m    466\u001b[39m meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mMlflowException\u001b[39m: Could not find experiment with ID 0"
     ]
    }
   ],
   "source": [
    "mlflow.xgboost.autolog(log_models=False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Crear el estudio de Optuna\n",
    "#    - Usamos TPE (Tree-structured Parzen Estimator) como sampler.\n",
    "#    - direction=\"minimize\" porque queremos minimizar el RMSE.\n",
    "# ------------------------------------------------------------\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Ejecutar la optimizaci√≥n (n_trials = n√∫mero de intentos)\n",
    "#    - Cada trial ejecuta la funci√≥n objetivo con un set distinto de hiperpar√°metros.\n",
    "#    - Abrimos un run \"padre\" para agrupar toda la b√∫squeda.\n",
    "# ------------------------------------------------------------\n",
    "with mlflow.start_run(run_name=\"XGBoost Hyperparameter Optimization (Optuna)\", nested=True):\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Recuperar y registrar los mejores hiperpar√°metros\n",
    "    # --------------------------------------------------------\n",
    "    best_params = study.best_params\n",
    "    # Asegurar tipos/campos fijos (por claridad y consistencia)\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "    best_params[\"seed\"] = 42\n",
    "    best_params[\"objective\"] = \"reg:squarederror\"\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Etiquetas del run \"padre\" (metadatos del experimento)\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"NYC Taxi Time Prediction Project\",\n",
    "        \"optimizer_engine\": \"optuna\",\n",
    "        \"model_family\": \"xgboost\",\n",
    "        \"feature_set_version\": 1,\n",
    "    })\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 7) Entrenar un modelo FINAL con los mejores hiperpar√°metros\n",
    "    #    (normalmente se har√≠a sobre train+val o con CV; aqu√≠ mantenemos el patr√≥n original)\n",
    "    # --------------------------------------------------------\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=100,\n",
    "        evals=[(valid, \"validation\")],\n",
    "        early_stopping_rounds=10,\n",
    "    )\n",
    "\n",
    "    # Evaluar y registrar la m√©trica final en validaci√≥n\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 8) Guardar artefactos adicionales (p. ej. el preprocesador)\n",
    "    # --------------------------------------------------------\n",
    "    pathlib.Path(\"preprocessor\").mkdir(exist_ok=True)\n",
    "    with open(\"preprocessor/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "\n",
    "    mlflow.log_artifact(\"preprocessor/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    # La \"signature\" describe la estructura esperada de entrada y salida del modelo:\n",
    "    # incluye los nombres, tipos y forma (shape) de las variables de entrada y el tipo de salida.\n",
    "    # MLflow la usa para validar datos en inferencia y documentar el modelo en el Model Registry.\n",
    "    # Si X_val es la matriz dispersa (scipy.sparse) salida de DictVectorizer:\n",
    "    feature_names = dv.get_feature_names_out()\n",
    "    input_example = pd.DataFrame(X_val[:5].toarray(), columns=feature_names)\n",
    "\n",
    "    # Para que las longitudes coincidan, usa el mismo slice en y_pred\n",
    "    signature = infer_signature(input_example, y_val[:5])\n",
    "\n",
    "    # Guardar el modelo del trial como artefacto en MLflow.\n",
    "    mlflow.xgboost.log_model(\n",
    "        booster,\n",
    "        name=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"workspace.default.nyc-taxi-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EXPERIMENT_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m runs = mlflow.search_runs(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     experiment_names=[\u001b[43mEXPERIMENT_NAME\u001b[49m],\n\u001b[32m      3\u001b[39m     order_by=[\u001b[33m\"\u001b[39m\u001b[33mmetrics.rmse ASC\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      4\u001b[39m     output_format=\u001b[33m\"\u001b[39m\u001b[33mlist\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Obtener el mejor run\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(runs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[31mNameError\u001b[39m: name 'EXPERIMENT_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[EXPERIMENT_NAME],\n",
    "    order_by=[\"metrics.rmse ASC\"],\n",
    "    output_format=\"list\"\n",
    ")\n",
    "\n",
    "# Obtener el mejor run\n",
    "if len(runs) > 0:\n",
    "    best_run = runs[0]\n",
    "    print(\"üèÜ Champion Run encontrado:\")\n",
    "    print(f\"Run ID: {best_run.info.run_id}\")\n",
    "    print(f\"RMSE: {best_run.data.metrics['rmse']}\")\n",
    "    print(f\"Params: {best_run.data.params}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontraron runs con m√©trica RMSE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m result = mlflow.register_model(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     model_uri=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbest_run\u001b[49m.info.run_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/model\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     name=model_name\n\u001b[32m      4\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'best_run' is not defined"
     ]
    }
   ],
   "source": [
    "result = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{best_run.info.run_id}/model\",\n",
    "    name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = result.version\n",
    "new_alias = \"Champion\"\n",
    "\n",
    "client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=new_alias,\n",
    "    version=result.version\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Anexo: c√≥mo resolver errores de OpenMP (`libomp` / `libgomp`) con XGBoost\n",
    "\n",
    "Cuando entrenas XGBoost, a veces aparecen errores tipo **‚Äúlibrary not loaded: libomp.dylib‚Äù** (macOS) o **‚Äúcannot open shared object file: libgomp.so.1‚Äù** (Linux) o problemas con **vcomp / OpenMP** (Windows). Aqu√≠ tienes soluciones por sistema operativo.\n",
    "\n",
    "---\n",
    "\n",
    "### üçè macOS (Intel y Apple Silicon)\n",
    "**S√≠ntoma com√∫n:**  \n",
    "`OSError: dlopen(... libxgboost.dylib ...): Library not loaded: @rpath/libomp.dylib`\n",
    "\n",
    "**Soluci√≥n r√°pida con Homebrew (recomendado):**\n",
    "```bash\n",
    "# Instalar / reinstalar OpenMP\n",
    "brew update\n",
    "brew install libomp || brew reinstall libomp\n",
    "\n",
    "# (opcional) Si sigues con el error en notebooks lanzados desde terminal:\n",
    "# export DYLD_LIBRARY_PATH antes de abrir Jupyter\n",
    "echo 'export DYLD_LIBRARY_PATH=\"/opt/homebrew/opt/libomp/lib:$DYLD_LIBRARY_PATH\"' >> ~/.zshrc\n",
    "source ~/.zshrc\n",
    "```\n",
    "\n",
    "**Alternativas:**\n",
    "- Si usas **Conda**: `conda install -c conda-forge xgboost libomp`  \n",
    "  (las builds de conda-forge suelen traer las dependencias resueltas).\n",
    "- En **Jupyter**, reinicia el kernel despu√©s de instalar `libomp`.\n",
    "- Si el consumo de hilos es demasiado alto en laptops:  \n",
    "  `export OMP_NUM_THREADS=4` (ajusta a tus cores).\n",
    "\n",
    "---\n",
    "\n",
    "### ü™ü Windows (PowerShell / CMD)\n",
    "**S√≠ntomas comunes:**\n",
    "- Errores de OpenMP/vcomp o fallos al cargar `xgboost.dll`.\n",
    "- En WSL (Ubuntu) ver la secci√≥n Linux.\n",
    "\n",
    "**Soluci√≥n:**\n",
    "1. Aseg√∫rate de usar **x64** y Python de 64 bits.\n",
    "2. Instala/actualiza el **Microsoft Visual C++ Redistributable (2015‚Äì2022)**.  \n",
    "   (Busca ‚ÄúMicrosoft Visual C++ Redistributable x64‚Äù en el sitio oficial de Microsoft e inst√°lalo).\n",
    "3. Reinstala XGBoost:\n",
    "   ```powershell\n",
    "   pip install --upgrade --force-reinstall xgboost\n",
    "   ```\n",
    "4. Si tu CPU es de pocos n√∫cleos o ves uso excesivo:\n",
    "   ```powershell\n",
    "   setx OMP_NUM_THREADS 4\n",
    "   ```\n",
    "   (Cierra y abre la terminal para que aplique).\n",
    "\n",
    "**Notas:**\n",
    "- Si usas **Conda**: `conda install -c conda-forge xgboost` suele resolver las DLLs.\n",
    "- En entornos corporativos restringidos, ejecuta terminal como **Administrador** para el redistributable.\n",
    "\n",
    "---\n",
    "\n",
    "### üêß Linux (Ubuntu/Debian, Fedora, Alpine, Docker)\n",
    "**S√≠ntoma com√∫n:**  \n",
    "`ImportError: libgomp.so.1: cannot open shared object file: No such file or directory`\n",
    "\n",
    "**Soluci√≥n (Ubuntu/Debian):**\n",
    "```bash\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y libgomp1\n",
    "```\n",
    "\n",
    "**Fedora/CentOS/RHEL:**\n",
    "```bash\n",
    "sudo dnf install -y libgomp   # o\n",
    "sudo yum install -y libgomp\n",
    "```\n",
    "\n",
    "**Alpine (musl):**\n",
    "```bash\n",
    "sudo apk add libgomp\n",
    "```\n",
    "\n",
    "**Docker (por ejemplo, python:3.11-slim):**\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends libgomp1 && rm -rf /var/lib/apt/lists/*\n",
    "RUN pip install xgboost\n",
    "```\n",
    "\n",
    "**WSL (Ubuntu):**  \n",
    "Sigue los pasos de Ubuntu/Debian y reinicia el kernel/notebook.\n",
    "\n",
    "**Control de hilos (opcional):**\n",
    "```bash\n",
    "export OMP_NUM_THREADS=4\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
