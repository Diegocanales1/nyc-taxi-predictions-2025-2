{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b75da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os, pickle\n",
    "from dotenv import load_dotenv\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestRegressor\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d1a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "load_dotenv(override=True)\n",
    "EXPERIMENT_NAME = \"Tarea 4\"\n",
    "\n",
    "mlflow.set_tracking_uri('databricks')\n",
    "experiment = mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4fe065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess(df, dv):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dv.transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b77b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "df_train = read_dataframe('../data/green_tripdata_2025-01.parquet')\n",
    "df_val = read_dataframe('../data/green_tripdata_2025-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2264558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "categorical = ['PU_DO']\n",
    "numerical = ['trip_distance']\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "X_val = preprocess(df_val, dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec542e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split for MLFlow register\n",
    "training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2025-01\")\n",
    "validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2025-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55573d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMatrix, specific for XGBoost\n",
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f320cf84",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Definir la funci贸n objetivo para Optuna\n",
    "#    - Recibe un `trial`, que se usa para proponer hiperpar谩metros.\n",
    "#    - Entrena un modelo con esos hiperpar谩metros.\n",
    "#    - Calcula la m茅trica de validaci贸n (RMSE) y la retorna (Optuna la minimizar谩).\n",
    "#    - Abrimos un run anidado de MLflow para registrar cada trial.\n",
    "# ------------------------------------------------------------\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    # Hiperpar谩metros MUESTREADOS por Optuna en CADA trial.\n",
    "    # Nota: usamos log=True para emular rangos log-uniformes (similar a loguniform).\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", math.exp(-3), 1.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\",   math.exp(-5), math.exp(-1), log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", math.exp(-6), math.exp(-1), log=True),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", math.exp(-1), math.exp(3), log=True),\n",
    "        \"objective\": \"reg:squarederror\",  \n",
    "        \"seed\": 42,                      \n",
    "    }\n",
    "\n",
    "    # Run anidado para dejar rastro de cada trial en MLflow\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"model_family\", \"xgboost\")  # etiqueta informativa\n",
    "        mlflow.log_params(params)                  # registra hiperpar谩metros del trial\n",
    "\n",
    "        # Entrenamiento con early stopping en el conjunto de validaci贸n\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, \"validation\")],\n",
    "            early_stopping_rounds=10,\n",
    "        )\n",
    "\n",
    "        # Predicci贸n y m茅trica en validaci贸n\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "        # Registrar la m茅trica principal\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # La \"signature\" describe la estructura esperada de entrada y salida del modelo:\n",
    "        # incluye los nombres, tipos y forma (shape) de las variables de entrada y el tipo de salida.\n",
    "        # MLflow la usa para validar datos en inferencia y documentar el modelo en el Model Registry.\n",
    "        signature = infer_signature(X_val, y_pred)\n",
    "\n",
    "        # Guardar el modelo del trial como artefacto en MLflow.\n",
    "        mlflow.xgboost.log_model(\n",
    "            booster,\n",
    "            name=\"model\",\n",
    "            input_example=X_val[:5],\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "    # Optuna minimiza el valor retornado\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee785e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.xgboost.autolog(log_models=False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Crear el estudio de Optuna\n",
    "#    - Usamos TPE (Tree-structured Parzen Estimator) como sampler.\n",
    "#    - direction=\"minimize\" porque queremos minimizar el RMSE.\n",
    "# ------------------------------------------------------------\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Ejecutar la optimizaci贸n (n_trials = n煤mero de intentos)\n",
    "#    - Cada trial ejecuta la funci贸n objetivo con un set distinto de hiperpar谩metros.\n",
    "#    - Abrimos un run \"padre\" para agrupar toda la b煤squeda.\n",
    "# ------------------------------------------------------------\n",
    "with mlflow.start_run(run_name=\"XGBoost Hyperparameter Optimization (Optuna)\", nested=True):\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Recuperar y registrar los mejores hiperpar谩metros\n",
    "    # --------------------------------------------------------\n",
    "    best_params = study.best_params\n",
    "    # Asegurar tipos/campos fijos (por claridad y consistencia)\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "    best_params[\"seed\"] = 42\n",
    "    best_params[\"objective\"] = \"reg:squarederror\"\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Etiquetas del run \"padre\" (metadatos del experimento)\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"NYC Taxi Time Prediction Project\",\n",
    "        \"optimizer_engine\": \"optuna\",\n",
    "        \"model_family\": \"xgboost\",\n",
    "        \"feature_set_version\": 1,\n",
    "    })\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 7) Entrenar un modelo FINAL con los mejores hiperpar谩metros\n",
    "    #    (normalmente se har铆a sobre train+val o con CV; aqu铆 mantenemos el patr贸n original)\n",
    "    # --------------------------------------------------------\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=100,\n",
    "        evals=[(valid, \"validation\")],\n",
    "        early_stopping_rounds=10,\n",
    "    )\n",
    "\n",
    "    # Evaluar y registrar la m茅trica final en validaci贸n\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 8) Guardar artefactos adicionales (p. ej. el preprocesador)\n",
    "    # --------------------------------------------------------\n",
    "    pathlib.Path(\"preprocessor\").mkdir(exist_ok=True)\n",
    "    with open(\"preprocessor/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "\n",
    "    mlflow.log_artifact(\"preprocessor/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    # La \"signature\" describe la estructura esperada de entrada y salida del modelo:\n",
    "    # incluye los nombres, tipos y forma (shape) de las variables de entrada y el tipo de salida.\n",
    "    # MLflow la usa para validar datos en inferencia y documentar el modelo en el Model Registry.\n",
    "    # Si X_val es la matriz dispersa (scipy.sparse) salida de DictVectorizer:\n",
    "    feature_names = dv.get_feature_names_out()\n",
    "    input_example = pd.DataFrame(X_val[:5].toarray(), columns=feature_names)\n",
    "\n",
    "    # Para que las longitudes coincidan, usa el mismo slice en y_pred\n",
    "    signature = infer_signature(input_example, y_val[:5])\n",
    "\n",
    "    # Guardar el modelo del trial como artefacto en MLflow.\n",
    "    mlflow.xgboost.log_model(\n",
    "        booster,\n",
    "        name=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c2f53a",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci贸n Objective\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 50),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"model_family\", \"random_forest\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        model = RandomForestRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        signature = infer_signature(X_val, y_pred)\n",
    "        mlflow.sklearn.log_model(model, \"model\", input_example=X_val[:5], signature=signature)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "\n",
    "# Optuna\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Ejecutar optimizaci贸n\n",
    "# ------------------------------------------------------------\n",
    "with mlflow.start_run(run_name=\"Random Forest Hyperparameter Optimization (Optuna)\", nested=True):\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_params[\"random_state\"] = 42\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"NYC Taxi Time Prediction Project\",\n",
    "        \"optimizer_engine\": \"optuna\",\n",
    "        \"model_family\": \"random_forest\",\n",
    "        \"feature_set_version\": 1,\n",
    "    })\n",
    "\n",
    "    model = RandomForestRegressor(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    pathlib.Path(\"preprocessor\").mkdir(exist_ok=True)\n",
    "    with open(\"preprocessor/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "    mlflow.log_artifact(\"preprocessor/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    feature_names = dv.get_feature_names_out()\n",
    "    input_example = pd.DataFrame(X_val[:5].toarray(), columns=feature_names)\n",
    "    signature = infer_signature(input_example, y_val[:5])\n",
    "\n",
    "    mlflow.sklearn.log_model(model, \"model\", input_example=input_example, signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrando el Champion y Challenger\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[EXPERIMENT_NAME],\n",
    "    order_by=[\"metrics.rmse ASC\"],\n",
    "    output_format=\"list\"\n",
    ")\n",
    "\n",
    "# Obtener el mejor run\n",
    "if len(runs) > 0:\n",
    "    best_run = runs[0]\n",
    "    challenger = runs[1]\n",
    "    print(\" Champion Run encontrado:\")\n",
    "    print(f\"Run ID: {best_run.info.run_id}\")\n",
    "    print(f\"RMSE: {best_run.data.metrics['rmse']}\")\n",
    "    print(f\"Params: {best_run.data.params}\")\n",
    "    print()\n",
    "    print(\" Challenger Encontrado\")\n",
    "    print(f\"Run ID: {challenger.info.run_id}\")\n",
    "    print(f\"RMSE: {challenger.data.metrics['rmse']}\")\n",
    "    print(f\"Params: {challenger.data.params}\")\n",
    "else:\n",
    "    print(\"锔 No se encontraron runs con m茅trica RMSE.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
